{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc0b27d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
      "\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
      "<head>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>历史天气查询|历史天气预报查询|历史气温查询|过去天气查询_历史天气查询网</title>\n",
      "<meta content=\"历史天气查询,历史天气预报,历史气温\" name=\"keywords\"/>\n",
      "<meta content=\"全球天气网（www.tianqi.com）提供全国各大城市的历史天气预报查询，历史气温查询，历史天气数据来源于城市当天的天气预报信息。\" name=\"description\"/>\n",
      "<meta content=\"format=xhtml;url=https://m.tianqi.com/lishi/\" http-equiv=\"mobile-agent\"/>\n",
      "<link href=\"https://m.tianqi.com/lishi/\" rel=\"canonical\"/>\n",
      "<link href=\"//staticls.tianqistatic.com/static/css/pub.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"//staticls.tianqistatic.com/static/css/global.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"//staticls.tianqistatic.com/static/css/history_weather.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<script src=\"//staticls.tianqistatic.com/static/js/jQuery.1.8.2.min.js\" type=\"text/javascript\"></s\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup#导入模块\n",
    "import urllib.request#导入模块\n",
    "import re #导入模块\n",
    "# 爬取天气网信息\n",
    "## 第一步：从天气网首页获取所有城市名以及其链接信息，构造 城市-城市拼音 的字典\n",
    "req = urllib.request.Request(url=\"http://lishi.tianqi.com/\",headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
    "page = urllib.request.urlopen(req).read() #获取天气网首页源代码\n",
    "bs = BeautifulSoup(page,'html.parser') \n",
    "#用BeautifulSoup将page转化为bs对象以便调用bs的相关方法 \n",
    "### 仔细分析网页源代码，寻找城市链接信息的标签规律，\n",
    "#发现都是名为a，属性target为_blank，且属性title为城市名历史天气形式的标签\n",
    "print(bs.decode()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0701c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "city_info = bs.find_all(\"a\",attrs={\"target\":\"_blank\",\"title\":re.compile(\"[\\w]+历史天气$\")}) \n",
    "\n",
    "city_names = [i.text for i in city_info] #标签对象的文字内容就是城市名\n",
    "\n",
    "print(city_info)\n",
    "print()\n",
    "print(city_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"/suyouqi/index.html\"\n",
    "#### str.split(char)：根据字符串char将字符串str进行分割，将分割后的字符串以列表形式返回，char默认为空白字符\n",
    "print(a.split(\"/index\"))\n",
    "print(a.split(\"/\")[1].split(\"/\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 标签对象的href属性中/index的前半部分就是城市拼音\n",
    "city_spelling = [i.attrs['href'].split(\"/index\")[0].replace(\"/\",\"\") for i in city_info] \n",
    "print(city_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dfc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(city_names)==len(city_spelling))\n",
    "#检查一下城市名和拼音序列是不是长度一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_name_spelling=dict(zip(city_names,city_spelling))\n",
    "#zip(city_names,city_spelling) 是将城市名字和城市拼音两个列表组建一个元组\n",
    "#dict(zip(city_names,city_spelling)) 将这个元组创造成一个字典\n",
    "print(dict_name_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703783bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 第二步：定义爬取天气数据的函数 #\n",
    "## 先定义一个稳健的获取网页信息的函数（不要求掌握，只是在实践中为避免一些常见的问题而构造的函数）\n",
    "import time \n",
    "import pandas as pd \n",
    "def get_webpage(url): \n",
    "    \"\"\" \n",
    "    从指定网址url获取网页源代码， \n",
    "    为了避免请求被阻拦，添加标头中的User-Agent信息 \n",
    "    为了避免由于网络不良导致程序一直等待响应而停滞不前，设置超时时间 \n",
    "    \"\"\"\n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0\"} \n",
    "    req = urllib.request.Request(url=url,headers=headers) \n",
    "    global webpage #由于后面函数迭代中的需要，定义全局变量webpage，否则在调用函数时可能会出现由于本地变量未提前声明而发生的错误 \n",
    "    try: \n",
    "        webpage = urllib.request.urlopen(req,timeout=60).read() \n",
    "    except: \n",
    "        time.sleep(10) #如果响应超时，则等待10秒后再请求网页 \n",
    "        get_webpage(url) \n",
    "    return webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义一个根据指定时间段和城市名爬取天气网信息的函数 \n",
    "def get_history_weather(yms,cities=city_names): \n",
    "    \n",
    "    \"\"\" \n",
    "    yms指定时间段：应为由YYYYMM形式的年月字符串组成的列表\n",
    "    cities指定城市名：应为需要获取天气信息的城市名组成的列表 \n",
    "    \"\"\" \n",
    "    history_weather = [] #创建一个空列表以储存获取的天气数据 \n",
    "#Step 1 传入城市名转换成城市拼音\n",
    "    for n in range(len(cities)): \n",
    "        city_spelling = dict_name_spelling[cities[n]] #根据城市名获取对应的城市拼音 \n",
    "        print(city_spelling)\n",
    "#Step 2 根据城市拼音+传入的年月信息定位到构造网址 \n",
    "        for ym in yms: \n",
    "            weather_url = \"http://lishi.tianqi.com/\"+city_spelling+\"/\"+ym+\".html\" \n",
    "    #Step 3 调用定义好的get_webpage函数获取网页源代码 \n",
    "            weather_page = get_webpage(weather_url) \n",
    "            soup = BeautifulSoup(weather_page,'html.parser') \n",
    "    #Step 4 分析网页，寻找天气数据的标签规律，发现每日天气数据包含在以ul为名，属性class的值为\"thrui\"的\n",
    "    #标签对象中所有名为li的子标签对象里 \n",
    "            weather = soup.find(\"ul\",attrs={\"class\":\"thrui\"}).find_all(\"li\") \n",
    "            for item in weather: \n",
    "                info = item.find_all(\"div\") #每日天气信息分日期、最高温度、最低温度、天气、风向分别在名为div的子标签对象里 \n",
    "                info = [i.text for i in info] #获取标签的文字内容，即为所需信息 \n",
    "                history_weather.append([cities[n]]+info) #将城市名和其天气信息合并到一个列表中，再添加到history_weather之中 \n",
    "                print(\"getting weather info:%s for %s\" %(cities[n],ym)) #打印下载进程         \n",
    "    weather_df = pd.DataFrame(history_weather) #将收集到的数据转化为pandas DataFrame \n",
    "    weather_df.columns = ['城市','日期','最高气温', '最低气温', '天气', '风向'] #为数据添加列名 \n",
    "    weather_df.to_excel('天气.xlsx',index=False) #数据量不大时可以放在excel中，如果数据量过大，可以考虑储存到csv中 \n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_history_weather(['201511'],['成都'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce235b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6483b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5330027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae46759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f56bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d3214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_history_weather(['201511','201611'],['上海','成都'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
